---
title: "Male CNS Connectivity Analysis"
author: "Katherina Eichler, Modified FLorian Kämpf"
date: "2025-04-09"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
editor_options: 
  markdown: 
    wrap: 72
---

# Introduction

This document performs an analysis of male CNS connectivity data. We
extract connectivity matrices, normalize the data using efficient sparse
matrix operations, and generate visualizations of input/output neuron
connectivity. The workflow includes: 
• Data extraction and preprocessing
• Construction and normalization of a sparse connectivity matrix 
• Extraction and processing of neuron annotations 
• Layer propagation computations 
• Aggregation and visualization via heatmaps and boxplots

#0 Load Required Libraries

```{r}
library(neuprintr)
library(arrow)
library(malecns)
library(bit64)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(Matrix)
library(cowplot)
library(coconat)  # for partner_summary2adjacency_matrix (if available)
library(coconatfly)
```

#1 Data Extraction and Preprocessing

##1.1  Extract Male CNS Annotations

```{r}
# Get male CNS annotations, filtering out unwanted statuses.
mdf <- mcns_dvid_annotations()
query.ids <- as.integer64(
  mdf$bodyid[!(mdf$status %in% c("Orphan", "PRT Orphan", "RT Orphan",
                                  "Unimportant", "Orphan hotknife",
                                  "Out of scope", "Glia", 
                                  "Orphan-artifact", NA))]
)
```

##1.2 Load the Flat Connectome

```{r}
path <- '/Users/fkampf/Downloads/snapshots_2025-02-11-a4c0d9-unlocked_flat-connectome_connectome-weights-2025-02-11-a4c0d9-unlocked-minconf-0.5-primary-only.feather'
conn_feather <- arrow::open_dataset(path,format = 'feather')

conn_feather.inmem <- conn_feather %>%
  select(body_pre, body_post, weight) %>%
  collect()

#Create the Sparse Adjacency Matrix

all_ids <- union(unique(conn_feather.inmem$body_pre), unique(conn_feather.inmem$body_post))
np_adj <- coconat::partner_summary2adjacency_matrix(conn_feather.inmem, 
                                                    inputcol = 'body_pre', 
                                                    outputcol = 'body_post', 
                                                    sparse = TRUE,
                                                    inputids = all_ids, 
                                                    outputids = all_ids,
                                                    standardise_input = FALSE)
```

##1.3 Matrix Scaling

##1.3.1 Column Scaling Function
```{r}
#' Efficient column scaling for sparse matrices
#'
#' @description Normalizes a matrix's columns by dividing each column by its total sum.
#'   In connectivity data, columns represent downstream neurons. This function converts raw
#'   input weights into percentages.
#'
#' @param A A sparse (or dense) matrix.
#' @param na.rm Logical flag indicating whether to set non-finite scaling factors to 0.
#'
#' @return A matrix with each column scaled to sum to 1 (or zero if the original sum was zero).
#'
#' @examples
#' library(Matrix)
#' set.seed(42)
#' A <- Matrix(rbinom(100, 10, 0.05), nrow = 10)
#' colScale(A)
colScale <- function(A, na.rm = TRUE) {
  scalefac <- 1 / Matrix::colSums(A)
  if (na.rm) scalefac[!is.finite(scalefac)] <- 0
  B <- A %*% Matrix::Diagonal(x = scalefac)
  B
}
```

##1.3.2 Compute the Input Percentage Matrix
```{r}
np_adj_per_in <- colScale(np_adj)
colnames(np_adj_per_in) <- colnames(np_adj)
```

##1.3.4 Restrict to Valid Neuron Bodies
```{r}
mdf = mcns_dvid_annotations()
query.ids = as.integer64(mdf$bodyid[!(mdf$status %in% c("Orphan","PRT Orphan", "RT Orphan",
                                                        "Unimportant","Orphan hotknife","Out of scope",
                                                        "Glia","Orphan-artifact",NA))])
query_info = mcns_neuprint_meta(query.ids)
query_info = query_info[!(query_info$status %in% c("Orphan",NA)),]
query.ids2 = na.omit(as.character(query_info$bodyid))

np_adj <- np_adj[rownames(np_adj) %in% query.ids2, colnames(np_adj) %in% query.ids2]
np_adj_per_in <- np_adj_per_in[rownames(np_adj_per_in) %in% query.ids2, colnames(np_adj_per_in) %in% query.ids2]
rm(query.ids2, conn_feather.inmem, conn_feather, mdf)
```

#2 Add Input/Output Neuron Annotations

##2.1 Process Annotations
```{r}
all_info <- mcns_body_annotations()
all_info <- all_info %>%
  mutate(
    type = case_when(
      grepl("putative_ppk23", receptor_type) ~ "m-cell",
      grepl("putative_ppk25", receptor_type) ~ "f-cell",
      TRUE ~ type
    )
  )

input.cell_types <- c("SAD051_b","SAD051_a",'AVLP721m','(JO-B)')
input.cell_types <- c("AN09B017","AN05B023",'AN05B102')
#input.cell_types <- c('m-cell','f-cell')
mf.downstream.ids <-all_info%>%filter(type %in% c('m-cell','f-cell'))%>%pull(bodyid)%>%unique()
mf.downstream.cfps <-cf_partner_summary(cf_ids(malecns=mf.downstream.ids),partners = 'o',threshold=5)
mf.downstream.top20 <- (mf.downstream.cfps %>%filter(!grepl('SN',type.post))%>%pull(type.post)%>%unique())[1:20]
input.cell_types<- c(input.cell_types,mf.downstream.top20)




input_ids<-all_info%>%filter(type %in% input.cell_types)%>%pull(bodyid)%>%unique()
input_info <- all_info[all_info$bodyid %in% input_ids, ]
input_info_sel <- input_info[, c("bodyid", "class", "group", "type", "instance", "soma_side", "root_side", "superclass")]

input_info_sel$soma_or_root_side <- ifelse(!is.na(input_info_sel$soma_side) & input_info_sel$soma_side != "",
                                            input_info_sel$soma_side,
                                            input_info_sel$root_side)


output.cell_types <- c("pMP2","pIP10",'vpoEN','vpoIN','AVLP721m')
output.cell_types <- c("pIP10","pMP2")
output.cell_types <- c(output.cell_types,all_info %>% filter(grepl('mAL_', type))%>%pull(type)%>%unique())
output.cell_types <- c(output.cell_types,all_info %>% filter(grepl('P1_', type))%>%pull(type)%>%unique())
#output.cell_types <- c(mf.downstream.top20)


output_ids <- all_info%>%filter(type %in% output.cell_types)%>%pull(bodyid)%>%unique()

output_info <- all_info[all_info$bodyid %in% output_ids, ]
output_info_sel <- output_info[, c("bodyid", "class", "group", "type", "instance", "soma_side", "root_side", "superclass")]
output_info_sel$soma_or_root_side <- ifelse(!is.na(output_info_sel$soma_side) & output_info_sel$soma_side != "",
                                             output_info_sel$soma_side,
                                             output_info_sel$root_side)
```

#3 Precalculate Layers and Compute Connectivity Scores

##3.1 Precalculate Layers

```{r}
desired_layers <- 3

#this is just creating a vector with the names of the layer. For example if desired_layers=3 --> layer_vec "v0" "v1" "v2" "v3".
layer_vec <- paste0("v", seq(from = 0, to = desired_layers)) 
#this just preallocates a list of the desired layer length (meaning if the dsired_layers=3 --> length(layer_list)==4 with layer 0 being the input layer)
layer_list <- vector("list", length(layer_vec))
#this just renames the indices of the layer_list
names(layer_list) <- layer_vec
#assign layer 0 to v0 in layer list, also it slices the row (aka input) to your input neurons
layer_list[["v0"]] <- np_adj_per_in[rownames(np_adj_per_in) %in% input_info_sel$bodyid, ]
#here you do the matrix multiplication
for (layer in 1:desired_layers) {
  layer_list[[layer + 1]] <- layer_list[[layer]] %*% np_adj_per_in
}
```

##3.2 Compute Connectivity Scores

We compute the input/output connectivity scores and assign connectivity
details for each input neuron type.

```{r}
#just based on your input ids get represented types
input_types <- unique(input_info_sel$type)
#for each neuron type in your input ids execute the following code
for (s in 1:length(input_types)) {
  #this is taking the current inpt type and initializes it as an variable assigning to it all the corresponding bodyids
  assign(input_types[s], na.omit(unique(input_info$bodyid[grepl(input_types[s], input_info$type)])))
}

#just based on your output ids get represented types
output_order <- sort(unique(output_info$type))

#preallocate an empty dataframe to save your connectivity scores
in_out_scores <- setNames(data.frame(matrix(ncol = 16, nrow = 0)),
                          c("bodyid", "conn_score", "ds_layer", "class", "group", "type", 
                            "instance", "soma_side", "rootSide", "superclass", 
                            "soma_or_root_side", "input", "in_side", "ipsi_contra"))
in_out_scores_all <- setNames(data.frame(matrix(ncol = 16, nrow = 0)),
                          c("bodyid", "conn_score", "ds_layer", "class", "group", "type", 
                            "instance", "soma_side", "rootSide", "superclass", 
                            "soma_or_root_side", "input", "in_side", "ipsi_contra"))

#for each neuron type in your input ids execute the following code
for (n in 1:length(input_types)) {
  #get for the current type the ids that are on the left vs right side
  startn_r <- as.character(na.omit(input_info_sel$bodyid[input_info_sel$type == input_types[n] & 
                                                            input_info_sel$soma_or_root_side == "R"]))
  startn_l <- as.character(na.omit(input_info_sel$bodyid[input_info_sel$type == input_types[n] & 
                                                            input_info_sel$soma_or_root_side == "L"]))
  
  #When there is at least one neuron on the right and left hemisphere
  if (length(startn_r) > 0 & length(startn_l) > 0) {

    #for cells on the left and right preallocate a list with the length of the desired layers also name the entries
    norm_list_l <- vector("list", length(layer_vec))
    names(norm_list_l) <- layer_vec
    norm_list_r <- vector("list", length(layer_vec))
    names(norm_list_r) <- layer_vec
    
    #for each desired layer execute the following code
    for (layer in 1:(desired_layers+1)) {
      #if there is at least one neuron of the current input type on the left 
      if (length(startn_l) > 1) {
        #This line sums the sparse matrix columns for the rows that match the current input neurons on the left 
        temp_layer_conn_str <- Matrix::colSums(layer_list[[layer]][na.omit(match(startn_l, rownames(layer_list[[layer]]))), ])
      } else {
        #you get back an empty sparse matrix with the same number of columns as the original since startn_l = character(0)
        temp_layer_conn_str <- layer_list[[layer]][na.omit(match(startn_l, rownames(layer_list[[layer]]))), ]
      }
      #noramlize each connection by mean scaling, colnames are also reassigned
      norm_list_l[[layer ]] <- setNames(as.vector(temp_layer_conn_str / mean(temp_layer_conn_str[temp_layer_conn_str > 0])),
                                           colnames(np_adj_per_in))
      #do the same things for right hemisphere neurons
      if (length(startn_r) > 1) {
        temp_layer_conn_str <- Matrix::colSums(layer_list[[layer]][na.omit(match(startn_r, rownames(layer_list[[layer]]))), ])
      } else {
        temp_layer_conn_str <- layer_list[[layer]][na.omit(match(startn_r, rownames(layer_list[[layer]]))), ]
      }
      norm_list_r[[layer]] <- setNames(as.vector(temp_layer_conn_str / mean(temp_layer_conn_str[temp_layer_conn_str > 0])),
                                           colnames(np_adj_per_in))
    }
    #preallocate and empty dataframe 
    out_r_scores_df <- setNames(data.frame(matrix(ncol = 3, nrow = 0)),
                                c("bodyid", "conn_score", "ds_layer"))
    #for each layer we calculated connectivity
    for (layer in 1:(desired_layers+1)) {
      #for each output_id extract the connectivity value
      out_r_scores <- norm_list_r[[layer]][names(norm_list_r[[layer]]) %in% output_ids]
      #add connectivity scores to dataframe
      df <- data.frame(bodyid = as.double(names(out_r_scores)), 
                       conn_score = out_r_scores,
                       ds_layer = layer, row.names = NULL)
      out_r_scores_df <- rbind(out_r_scores_df, df)
    }
    #get the layer where maximum connectivity appears
    out_r_scores_df %>%
      group_by(bodyid) %>%
      slice(which.max(conn_score)) -> out_r_scores_df_max
    
    #add info to maximum connectivity layer
    out_r_scores_df_max_info <- left_join(out_r_scores_df_max, output_info_sel, by = "bodyid")
    out_r_scores_df_all_info <- left_join(out_r_scores_df, output_info_sel, by = "bodyid")
    out_r_scores_df_max_info$input <- input_types[n]
    out_r_scores_df_all_info$input <- input_types[n]
    out_r_scores_df_max_info$in_side <- "R"
    out_r_scores_df_all_info$in_side <- "R"
    
    #preallocate an emptuy dataframe for left hemisphere
    out_l_scores_df <- setNames(data.frame(matrix(ncol = 3, nrow = 0)),
                                c("bodyid", "conn_score", "ds_layer"))
    for (layer in 1:(desired_layers+1)) {
      #for each output_id extract the connectivity value
      out_l_scores <- norm_list_l[[layer]][names(norm_list_l[[layer]]) %in% output_ids]
      #add connectivity scores to dataframe
      df <- data.frame(bodyid = as.double(names(out_l_scores)), conn_score = out_l_scores, ds_layer = layer, row.names = NULL)
      out_l_scores_df <- rbind(out_l_scores_df, df)
    }
    #get the layer where maximum connectivity appears
    out_l_scores_df %>%
      group_by(bodyid) %>%
      slice(which.max(conn_score)) -> out_l_scores_df_max
    
    #add info to maximum connectivity layer
    out_l_scores_df_max_info <- left_join(out_l_scores_df_max, output_info_sel, by = "bodyid")
    out_l_scores_df_all_info <- left_join(out_l_scores_df, output_info_sel, by = "bodyid")
    out_l_scores_df_max_info$input <- input_types[n]
    out_l_scores_df_all_info$input <- input_types[n]
    out_l_scores_df_max_info$in_side <- "L"
    out_l_scores_df_all_info$in_side <- "L"
    
    #bring left and right together
    out_scores <- rbind(out_r_scores_df_max_info, out_l_scores_df_max_info)
    out_scores_all <- rbind(out_l_scores_df_all_info, out_r_scores_df_all_info)
    out_scores$ipsi_contra <- NA
    out_scores_all$ipsi_contra <- NA
    out_scores$ipsi_contra[out_scores$soma_or_root_side == out_scores$in_side] <- "ipsi"
    out_scores$ipsi_contra[out_scores$soma_or_root_side != out_scores$in_side] <- "contra"
    out_scores_all$ipsi_contra[out_scores_all$soma_or_root_side == out_scores_all$in_side] <- "ipsi"
    out_scores_all$ipsi_contra[out_scores_all$soma_or_root_side != out_scores_all$in_side] <- "contra"
    
    in_out_scores <- rbind(in_out_scores, out_scores)
    in_out_scores_all <- rbind(in_out_scores_all, out_scores_all)
  }
}
```

# 4 Aggregation and Visualization

## 4.1 Aggregate the Connectivity Scores

```{r}
#see per start type, ipsi_contra and target type what is the mean conn_score and in which layer it appears
in_out_scores %>%
  group_by(input, type, ipsi_contra) %>%
  summarise_at(vars("conn_score", "ds_layer"), mean) -> in_out_scores_mean

in_out_scores_all %>%
  mutate(type=paste(bodyid,type))%>%
  group_by(input, type, ipsi_contra) %>%
  summarise_at(vars("conn_score", "ds_layer"), mean) -> in_out_scores_mean_id

#only ipsi
in_out_scores_mean_id %>% filter(ipsi_contra == "ipsi") -> in_out_scores_mean_id_ipsi
in_out_scores_mean %>% filter(ipsi_contra == "ipsi") -> in_out_scores_mean_ipsi

in_out_scores_mean_ipsi_m <- tidyr::pivot_wider(in_out_scores_mean_ipsi[, c("input", "conn_score", "type")],
                                                names_from = "input", values_from = "conn_score")
in_out_scores_mean_id_ipsi_m <- tidyr::pivot_wider(in_out_scores_mean_id_ipsi[, c("input", "conn_score", "type")],
                                                names_from = "input", values_from = "conn_score")

in_out_scores_mean_ipsi_m <- as.matrix(in_out_scores_mean_ipsi_m[, -1])
in_out_scores_mean_id_ipsi_m <- as.matrix(in_out_scores_mean_id_ipsi_m[, -1])
in_out_scores_mean_id_ipsi_m[is.na(in_out_scores_mean_id_ipsi_m)]=0
clust <- hclust(dist(t(in_out_scores_mean_ipsi_m)))
clust_id <- hclust(dist(t(in_out_scores_mean_id_ipsi_m)))
my_cols_fun <- colorRampPalette(c("purple","orange",'green'))
```

## 4.2 Plot a Heatmap (per type)

```{r}
figure_heatmap <- ggplot(as_tibble(in_out_scores_mean), aes(x = factor(type, level = output_order), y = input)) +
  geom_point(aes(col = ds_layer, size = conn_score), shape = 15) +
  theme_minimal() +
  theme(legend.position = 'right', text = element_text(color = 'grey40')) +
  scale_size_area(max_size = 10) +
  scale_colour_gradientn(colours = my_cols_fun(desired_layers), limits = c(1, desired_layers+1)) +
  scale_y_discrete(limits = colnames(in_out_scores_mean_ipsi_m)[clust$order]) +
  guides(colour = guide_legend(override.aes = list(size = 10))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        text = element_text(size = 14, family = "Arial"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
figure_heatmap
```
## 4.3 Plot a Heatmap (by id)

```{r}
figure_heatmap <- ggplot(as_tibble(in_out_scores_mean_id), 
                         aes(x = factor(type, level = unique(in_out_scores_mean_id$type)), y = input)) +
  geom_point(aes(col = ds_layer, size = conn_score), shape = 15) +
  theme_minimal() +
  theme(legend.position = 'right', text = element_text(color = 'grey40')) +
  scale_size_area(max_size = 5) +
  scale_colour_gradientn(colours = my_cols_fun(desired_layers+1), limits = c(1, desired_layers+1)) +
  scale_y_discrete(limits = colnames(in_out_scores_mean_id_ipsi_m)[clust_id$order]) +
  guides(colour = guide_legend(override.aes = list(size = 10))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        text = element_text(size = 14, family = "Arial"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
figure_heatmap
```
## 4.4 Plot with dendrogram

```{r}
library(ggdendro)
library(patchwork)
library(ggplot2)




# 1. compute clustering on your matrix
clust <- hclust(dist(t(in_out_scores_mean_ipsi_m)))


in_out_scores_mean_ipsi_m_norm <- apply(in_out_scores_mean_ipsi_m, 2, function(x) {
  (x - min(x, na.rm=TRUE)) / (max(x, na.rm=TRUE) - min(x, na.rm=TRUE))
})
# preserve dimnames
dimnames(in_out_scores_mean_ipsi_m_norm) <- dimnames(in_out_scores_mean_ipsi_m)
in_out_scores_mean_ipsi_m_norm     <- scale(in_out_scores_mean_ipsi_m, center = TRUE, scale = TRUE)
clust <- hclust(dist(t(in_out_scores_mean_ipsi_m_norm)))


# 2. extract dendrogram data
dd <- dendro_data(clust, type = "rectangle")

# 3. build a horizontal dendrogram (root on left, leaves align with your rows)
dendro_plot <- ggplot() +
  geom_segment(data = segment(dd),
               aes(x = y, y = x, xend = yend, yend = xend)) +
  scale_y_continuous(breaks = seq_along(clust$order),
                     labels = clust$labels[clust$order],
                     expand = c(0,0)) +
  scale_x_reverse(expand = c(0,0)) +
  theme_void()

# 4. your heatmap‐style tile plot, with inputs reordered by the same clustering
tile_plot <- ggplot(as_tibble(in_out_scores_mean),
                    aes(x = factor(type, levels = output_order),
                        y = factor(input, levels = clust$labels[clust$order]))) +
  geom_point(aes(col = ds_layer, size = conn_score),
             shape = 15) +
  scale_size_area(max_size = 10) +
  scale_colour_gradientn(colours = my_cols_fun(desired_layers),
                        limits = c(1, desired_layers + 1)) +
  guides(colour = guide_legend(override.aes = list(size = 10))) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title = element_blank(),
        text = element_text(size = 14, family = "Arial"))

# 5. combine them side by side
dendro_plot + tile_plot + plot_layout(widths = c(1.5, 5))
```


figure_heatmap

Boxplots for Connectivity Scores

```{r}
for (nth in 1:length(input_types)) {
  in_out_scores_type <- in_out_scores[in_out_scores$input == input_types[nth] & in_out_scores$type %in% output_order, ]
  
  type_score <- ggplot(in_out_scores_type, aes(x = factor(type, level = output_order), y = conn_score)) +
    geom_boxplot(fill = "#8B008B") +
    ylab("Score") + xlab("Output Neurons") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 10),
          panel.background = element_rect(fill = "white", colour = "black"),
          panel.grid = element_line(colour = "grey", linewidth = 0.2)) +
    ylim(0, ceiling(max(in_out_scores_type$conn_score))) +
    facet_grid(. ~ factor(ipsi_contra, levels = c("ipsi", "contra")), scales = "fixed")
  
  type_layer <- ggplot(in_out_scores_type, aes(x = factor(type, level = output_order), y = ds_layer)) +
    geom_boxplot(fill = "#8B008B") +
    ylab("Layer") + xlab("Output Neurons") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 10),
          panel.background = element_rect(fill = "white", colour = "black"),
          panel.grid = element_line(colour = "grey", linewidth = 0.2)) +
    ylim(1, desired_layers+1) +
    facet_grid(. ~ factor(ipsi_contra, levels = c("ipsi", "contra")), scales = "fixed")
  
  legend <- cowplot::get_legend(
    type_score +
      guides(color = guide_legend(nrow = 1)) +
      theme(legend.position = "bottom")
  )
  title <- cowplot::ggdraw() +
    cowplot::draw_label(paste0(input_types[nth], " connectivity to leg MNs"), fontface = 'bold')
  
  figure_nwh <- cowplot::plot_grid(
    type_score + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "none", plot.margin = margin(0.1,0.1,0,0.3, "cm")),
    type_layer + theme(legend.position = "none", strip.background = element_blank(), strip.text.x = element_blank(), plot.margin = margin(0.1,0.1,0,0.3, "cm")),
    ncol = 1, common.legend = FALSE, rel_heights = c(1.3, 0.8), align = "v", vjust = 0, axis = "rlbt"
  )
  figure2_nwh <- cowplot::plot_grid(title, legend, nrow = 1, rel_widths = c(1,1))
  figure3_nwh <- cowplot::plot_grid(figure2_nwh, figure_nwh, ncol = 1, rel_heights = c(0.1,1))
  ggsave(paste0("k.effective.connectivity.plots/", input_types[nth], "_combined_plot.pdf"),
         figure3_nwh, dev = cairo_pdf, width = 4715, height = 3295, units = "px")
}
```

Conclusion

This document demonstrates a full workflow for processing male CNS
connectivity data. We: 
• Extract and preprocess connectivity andannotation data, 
• Normalize a large sparse connectivity matrix via efficient scaling, 
• Compute layer-based connectivity scores, 
• And visualize results using heatmaps and boxplots.

This report is intended to be reproducible and easily modifiable for
further analysis. Enjoy the analysis!
